{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4215f3",
   "metadata": {},
   "source": [
    "#### Notebook for image preprocessing required in training the 3D-UNet for fine AC-PC localization\n",
    "\n",
    "##### Steps\n",
    "* Grab the coarse localized and true AC-PC landmarks, output from CoarseLocalization_Slicer.ipynb\n",
    "* Grab the skull stripped brain scans, also output from CoarseLocalization_Slicer.ipynb\n",
    "* Apply rotational augmentations, compute the corresponding 2 channel input patches and intermediately processed 4 channel       heatmap patches for 3D-UNet training. Also apply rotations to the coarse localized and true AC-PC landmarks\n",
    "* Write information required for 3D-UNet training. This involves the image coordinates of the coarse localized and true\n",
    "  AC-PC coordinates, along with their rotated version. It also involves the scaling factors required to modulate the \n",
    "  gaussian heatmaps and assemble the full 6-channel ground-truth required for 3D-UNet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os, re, time, sys\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image(image_arr, window_center, window_width):\n",
    "    \"\"\"Windows a volume to be within the given soft-tissue HU range\n",
    "    \n",
    "    Args: \n",
    "        image_arr: numpy array of the image volume\n",
    "        window_center: midpoint of the desired HU range\n",
    "        window_width: total width of the desired HU range around the window_center\n",
    "    Returns: \n",
    "        window_image: windowed image for optimal soft tissue viewing\n",
    "    \n",
    "    \"\"\"\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    \n",
    "    window_image = image_arr.copy()\n",
    "    window_image[window_image < img_min] = img_min\n",
    "    window_image[window_image > img_max] = img_max\n",
    "    return window_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, physical_coordinates, angles, resampling_type = 'linear', dimension = 3):\n",
    "    \"\"\"Rotates a 3D image and its associated landmarks based on the provided angles\n",
    "    \n",
    "    Args:\n",
    "        image: SITK image object that needs to be rotated\n",
    "        physical_coordinates: list of physical coordinates of associated landmarks\n",
    "        angles: desired 3D angle of rotation\n",
    "        resampling_type: linear or bspline - type of resampling used in generating the rotated image\n",
    "        dimension: image dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    #unpack the physical coordinates of associated AC-PC landmarks (true and coarse)\n",
    "    ac_true_phys_coordinates = physical_coordinates[:3]\n",
    "    pc_true_phys_coordinates = physical_coordinates[3:6]   \n",
    "    ac_phys_coordinates = physical_coordinates[6:9]  \n",
    "    pc_phys_coordinates = physical_coordinates[9:]\n",
    "    \n",
    "    #unpack theta values (for image rotation) and convert to radians\n",
    "    theta_radians_x, theta_radians_y, theta_radians_z  = np.deg2rad(angles[0]), np.deg2rad(angles[1]), np.deg2rad(angles[2])\n",
    "    \n",
    "    #define the 3D rotational transformation\n",
    "    transform_x = sitk.AffineTransform(dimension)\n",
    "    transform_x.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
    "    \n",
    "    transform_y = sitk.AffineTransform(dimension)\n",
    "    transform_y.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
    "    \n",
    "    transform_z = sitk.AffineTransform(dimension)\n",
    "    transform_z.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
    "\n",
    "    transform_cor = sitk.AffineTransform(dimension)\n",
    "    transform_cor.SetCenter(image.TransformContinuousIndexToPhysicalPoint(np.array(image.GetSize())//2.0))\n",
    "    \n",
    "    matrix_x = np.array([[1.0, 0.0, 0.0],\n",
    "                         [0.0, np.cos(theta_radians_x), -np.sin(theta_radians_x)],\n",
    "                         [0.0, np.sin(theta_radians_x), np.cos(theta_radians_x)]]) #rotation around the x axis \n",
    "    \n",
    "    matrix_y = np.array([[np.cos(theta_radians_y), 0.0, np.sin(theta_radians_y)],\n",
    "                         [0.0, 1.0, 0.0],\n",
    "                         [-np.sin(theta_radians_y), 0.0, np.cos(theta_radians_y)]])  #rotation around the y axis \n",
    "    \n",
    "    matrix_z = np.array([[np.cos(theta_radians_z), -np.sin(theta_radians_z), 0.0],\n",
    "                         [np.sin(theta_radians_z),  np.cos(theta_radians_z), 0.0],  #rotation around the z axis \n",
    "                         [0.0, 0.0, 1.0]])\n",
    "\n",
    "    matrix_cor = np.array(image.GetDirection()).reshape(3,3)    \n",
    "    \n",
    "    transform_x.SetMatrix(matrix_x.ravel())\n",
    "    transform_y.SetMatrix(matrix_y.ravel()) \n",
    "    transform_z.SetMatrix(matrix_z.ravel())\n",
    "    transform_cor.SetMatrix(matrix_cor.ravel())\n",
    "    \n",
    "    composite_transform = sitk.CompositeTransform([transform_x, transform_y, transform_z, transform_cor])\n",
    "    \n",
    "    #derive the physical coordinates of the bounding box of the given image\n",
    "    extreme_points = [image.TransformIndexToPhysicalPoint((0,0,0)), \n",
    "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,0)),\n",
    "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),0)),\n",
    "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),0)),\n",
    "                      image.TransformIndexToPhysicalPoint((0,0,image.GetDepth())), \n",
    "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),0,image.GetDepth())),\n",
    "                      image.TransformIndexToPhysicalPoint((image.GetWidth(),image.GetHeight(),image.GetDepth())),\n",
    "                      image.TransformIndexToPhysicalPoint((0,image.GetHeight(),image.GetDepth()))]\n",
    "    \n",
    "    #obtain the points where the extreme points of the image get mapped to, when they are transformed. This is required to \n",
    "    #specify the origin of the resampled and rotated image. Note that SITK uses the inverse of the specified transformation \n",
    "    inv_transform = composite_transform.GetInverse()\n",
    "\n",
    "    extreme_points_transformed = [inv_transform.TransformPoint(pnt) for pnt in extreme_points]\n",
    "    min_x = min(extreme_points_transformed)[0]\n",
    "    min_y = min(extreme_points_transformed, key=lambda p: p[1])[1]\n",
    "    min_z = min(extreme_points_transformed, key=lambda p: p[2])[2]\n",
    "    max_x = max(extreme_points_transformed)[0]\n",
    "    max_y = max(extreme_points_transformed, key=lambda p: p[1])[1]\n",
    "    max_z = max(extreme_points_transformed, key=lambda p: p[2])[2]\n",
    "\n",
    "    #transform the physical coordinates of the associated landmarks \n",
    "    landmarks_transformed = [inv_transform.TransformPoint(pnt) for pnt in \n",
    "                                                 [ac_true_phys_coordinates, pc_true_phys_coordinates, \n",
    "                                                    ac_phys_coordinates, pc_phys_coordinates]]\n",
    "    \n",
    "    \n",
    "    # Use the original spacing (arbitrary decision).\n",
    "    output_spacing = image.GetSpacing()\n",
    "    # Identity direction cosine matrix.   \n",
    "    output_direction = [1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0]\n",
    "    # Define the new origin.\n",
    "    output_origin = [min_x, min_y, min_z]     \n",
    "    #same size as input\n",
    "    output_size = image.GetSize()\n",
    "    \n",
    "    #resample the image in its rotated space\n",
    "    if resampling_type == 'linear':\n",
    "        resampler = sitk.sitkLinear\n",
    "    else:\n",
    "        resampler = sitk.BSplineResampler\n",
    "    \n",
    "    rotated_image = sitk.Resample(image, output_size, composite_transform, resampler, output_origin, output_spacing,\n",
    "                                  output_direction, defaultPixelValue = -3)\n",
    "    \n",
    "    return rotated_image, landmarks_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_processing(scan_id, rot_id, img_arr, patch_size, ac_true_coords, pc_true_coords,\n",
    "                       ac_pred_coords, pc_pred_coords, sigma_list, write_path):\n",
    "    \n",
    "    \n",
    "    \"\"\"Generates ground-truth patches for the 3D-UNet. \n",
    "    \n",
    "    Args:\n",
    "        scan_id (str): Scan identifier.\n",
    "        rot_id (int): Rotation identifier.\n",
    "        img_arr (numpy array): The image data, windowed between 0-80/100 HU\n",
    "        patch_size (int) : patch-size\n",
    "        ac_true_coords (tuple of float): True AC coordinates in the image reference system. \n",
    "        pc_true_coords (tuple of float): True PC coordinates in the image reference system. \n",
    "        ac_pred_coords (tuple of float): Predicted AC coordinates from registration, in the image reference system. \n",
    "        pc_pred_coords (tuple of float): Predicted PC coordinates from registration, in the image reference system. \n",
    "        sigma_list(lsit of int): List of sigmas (standard deviation) to modulate the Gaussians with.\n",
    "        write_path (string): Path to where the processed heatmap patches should be written. \n",
    " \n",
    "    Returns:\n",
    "        scaling_factors_df_sigma (pandas dataframe): Contains the modulation factors for gaussian heatmap patches for \n",
    "        sigmas [4,6,8,10,12,14] \n",
    "\n",
    "    Implementation details:\n",
    "        Define the heatmaps around the true landmarks (these include rotated positions). For each sigma, find the \n",
    "        modulating factors. Chop the heatmaps up based on the patch_size and save them. \n",
    "    \"\"\"\n",
    "    \n",
    "    #unpack predicted and true AC-PC coordinates\n",
    "    ac_x, ac_y, ac_z = ac_true_coords[0], ac_true_coords[1], ac_true_coords[2]\n",
    "    pc_x, pc_y, pc_z = pc_true_coords[0], pc_true_coords[1], pc_true_coords[2]\n",
    "\n",
    "    ac_x_pred, ac_y_pred, ac_z_pred = ac_pred_coords[0], ac_pred_coords[1], ac_pred_coords[2]\n",
    "    pc_x_pred, pc_y_pred, pc_z_pred = pc_pred_coords[0], pc_pred_coords[1], pc_pred_coords[2]\n",
    "    \n",
    "    #its more efficient to store the spatial locations of the image array and the associated value of the gaussian heatmap\n",
    "    #at those values rather than doing passes over the 3D image dimensions (i, j, k) and computing this as a 3D array to begin with\n",
    "    gaussian_heatmap_df = pd.DataFrame({'z':np.where(img_arr > -1)[0],\n",
    "                                        'y':np.where(img_arr > -1)[1], \n",
    "                                        'x':np.where(img_arr > -1)[2]})\n",
    "    \n",
    "    #This only computes the (x-mu_x)**2 + (y-mu_y)**2 + (z-mu_z)**2 part of the gaussian heatmap. \n",
    "    #These intermediate heatmaps get modulated by the chosen sigma and exponentiated in a data loader process during training\n",
    "    gaussian_heatmap_df['ac_val'] = ((gaussian_heatmap_df['z']-ac_z)**2 +\n",
    "                                          (gaussian_heatmap_df['y'] - ac_y)**2 + \n",
    "                                          (gaussian_heatmap_df['x'] - ac_x)**2)\n",
    "    gaussian_heatmap_df['pc_val'] = ((gaussian_heatmap_df['z']-pc_z)**2 +\n",
    "                                          (gaussian_heatmap_df['y'] - pc_y)**2 + \n",
    "                                          (gaussian_heatmap_df['x'] - pc_x)**2)\n",
    "\n",
    "\n",
    "    gaussian_heatmap_ac = gaussian_heatmap_df['ac_val'].values.reshape(img_arr.shape)\n",
    "\n",
    "    gaussian_heatmap_pc = gaussian_heatmap_df['pc_val'].values.reshape(img_arr.shape)\n",
    "    \n",
    "    #for all possible sigma values, calculate the minimum and maximum values of the sigma-modulated gaussian heatmaps\n",
    "    #these values will be used to scale the heatmaps during training to obtain a normalized (0-1) heatmap\n",
    "    scaling_factors_df_sigma_all = pd.DataFrame()\n",
    "    for sigma in sigma_list:\n",
    "        gaussian_heatmap_ac_sigma = np.exp(-1/(2*sigma**2) * gaussian_heatmap_ac)    \n",
    "        gaussian_heatmap_pc_sigma = np.exp(-1/(2*sigma**2) * gaussian_heatmap_pc)\n",
    "    \n",
    "        scaling_factors_df_sigma_all = pd.concat([scaling_factors_df_sigma_all, \n",
    "                                                  pd.DataFrame({'scan_id':[scan_id],\n",
    "                                                                'rot_id':[rot_id], 'sigma':[sigma],\n",
    "                                                                'min_gaussian_heatmap_ac':[gaussian_heatmap_ac_sigma.min()],\n",
    "                                                                'max_gaussian_heatmap_ac':[gaussian_heatmap_ac_sigma.max()],\n",
    "                                                                'min_gaussian_heatmap_pc':[gaussian_heatmap_pc_sigma.min()],\n",
    "                                                                'max_gaussian_heatmap_pc':[gaussian_heatmap_pc_sigma.max()]})])\n",
    "    \n",
    "    #patch the heatmap up based on the coarse localized AC-PC. Note that we do not need to store full heatmaps\n",
    "    #as the sigma modulation is on the voxel level. This trick enables us to work in memory-constrained setups. \n",
    "    ac_patch_ac_hm = gaussian_heatmap_ac[(int(np.round(ac_z_pred) - patch_size//2)):(int(np.round(ac_z_pred) + patch_size//2)),\n",
    "                                         (int(np.round(ac_y_pred) - patch_size//2)):(int(np.round(ac_y_pred) + patch_size//2)),\n",
    "                                         (int(np.round(ac_x_pred) - patch_size//2)):(int(np.round(ac_x_pred) + patch_size//2))]  \n",
    "    ac_patch_pc_hm = gaussian_heatmap_pc[(int(np.round(ac_z_pred) - patch_size//2)):(int(np.round(ac_z_pred) + patch_size//2)),\n",
    "                                         (int(np.round(ac_y_pred) - patch_size//2)):(int(np.round(ac_y_pred) + patch_size//2)),\n",
    "                                         (int(np.round(ac_x_pred) - patch_size//2)):(int(np.round(ac_x_pred) + patch_size//2))]\n",
    "    pc_patch_ac_hm = gaussian_heatmap_ac[(int(np.round(pc_z_pred) - patch_size//2)):(int(np.round(pc_z_pred) + patch_size//2)),\n",
    "                                         (int(np.round(pc_y_pred) - patch_size//2)):(int(np.round(pc_y_pred) + patch_size//2)),\n",
    "                                         (int(np.round(pc_x_pred) - patch_size//2)):(int(np.round(pc_x_pred) + patch_size//2))]\n",
    "    pc_patch_pc_hm = gaussian_heatmap_pc[(int(np.round(pc_z_pred) - patch_size//2)):(int(np.round(pc_z_pred) + patch_size//2)),\n",
    "                                         (int(np.round(pc_y_pred) - patch_size//2)):(int(np.round(pc_y_pred) + patch_size//2)),\n",
    "                                         (int(np.round(pc_x_pred) - patch_size//2)):(int(np.round(pc_x_pred) + patch_size//2))]\n",
    "    \n",
    "    #assemble the intermediately processed heatmap. Note that these do not contain the background channel as the\n",
    "    #background channel values depend upon the sigma modulated AC and PC channels, which will be computed on the fly during \n",
    "    #training. \n",
    "    gt_pat = np.concatenate((pc_patch_ac_hm, ac_patch_ac_hm, pc_patch_pc_hm, ac_patch_pc_hm)).reshape(4, patch_size, patch_size, patch_size)\n",
    "\n",
    "\n",
    "    hm_write_path = write_path / scan_id\n",
    "    if not os.path.exists(hm_write_path):\n",
    "        os.makedirs(hm_write_path, exist_ok=True)\n",
    "    with open(os.path.join(str(hm_write_path.resolve()), f'hm_patches_Rot_{rot_id}.npy'), mode='wb+') as f:\n",
    "        np.save(f, gt_pat)      \n",
    "\n",
    "    return scaling_factors_df_sigma_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c0ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_patches(scan_id, rot_id, img_arr, patch_size, ac_pred_coords, pc_pred_coords, write_path):\n",
    "    \n",
    "\n",
    "    \"\"\"Generates input patches for the 3D-UNet. \n",
    "\n",
    "    Args:\n",
    "        scan_id (str): Scan identifier.\n",
    "        rot_id (int): Rotation identifier.\n",
    "        img_arr (numpy array): The image data, windowed between 0-80/100 HU\n",
    "        patch_size (tuple of int) : 3D patch-size.\n",
    "        ac_pred_coords (tuple of float): Predicted AC coordinates from registration, in the image reference system. \n",
    "        pc_pred_coords (tuple of float): Predicted PC coordinates from registration, in the image reference system. \n",
    "        write_path (string): Path to where the processed heatmap patches should be written\n",
    "\n",
    "    \"\"\"\n",
    "    #gather coarse AC-PC coordinates to crop the input\n",
    "    ac_x_pred, ac_y_pred, ac_z_pred = ac_pred_coords[0], ac_pred_coords[1], ac_pred_coords[2]\n",
    "    pc_x_pred, pc_y_pred, pc_z_pred = pc_pred_coords[0], pc_pred_coords[1], pc_pred_coords[2]\n",
    "\n",
    "    #crop image patches of size patch_size around the coarse landmarks\n",
    "    voxel_patch_ac = img_arr[(int(np.round(ac_z_pred))-patch_size//2):(int(np.round(ac_z_pred))+patch_size//2),\n",
    "                             (int(np.round(ac_y_pred))-patch_size//2):(int(np.round(ac_y_pred))+patch_size//2),\n",
    "                             (int(np.round(ac_x_pred))-patch_size//2):(int(np.round(ac_x_pred))+patch_size//2)]\n",
    "\n",
    "    voxel_patch_pc = img_arr[(int(np.round(pc_z_pred))-patch_size//2):(int(np.round(pc_z_pred))+patch_size//2),\n",
    "                             (int(np.round(pc_y_pred))-patch_size//2):(int(np.round(pc_y_pred))+patch_size//2),\n",
    "                             (int(np.round(pc_x_pred))-patch_size//2):(int(np.round(pc_x_pred))+patch_size//2)]\n",
    "    #concatenate AC and PC channels to form the 2 channel input\n",
    "    input_pat = np.concatenate((voxel_patch_pc,voxel_patch_ac)).reshape(2, patch_size, patch_size, patch_size)\n",
    "\n",
    "    #save the input to given location\n",
    "    ip_write_path = write_path / scan_id\n",
    "    if not os.path.exists(ip_write_path):\n",
    "        os.makedirs(ip_write_path, exist_ok=True)\n",
    "    with open(os.path.join(str(ip_write_path.resolve()), f'input_patches_Rot_{rot_id}.npy'), mode='wb+') as f:\n",
    "        np.save(f, input_pat)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bbdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scan(scan_id):\n",
    "    \n",
    "    #read the axial image in\n",
    "    axial_img_path = str((data_path / str(scan_id).lstrip(os.sep) / \"Axial brain.nii\").resolve())\n",
    "\n",
    "    try:            \n",
    "        img = sitk.ReadImage(axial_img_path)\n",
    "    except Exception as e: \n",
    "        sys.exit(f'Image read error for scan {scan_id}: {e}')\n",
    "\n",
    "    img_labels = all_landmarks[all_landmarks['scan_id'] == scan_id][['ac_gt', 'pc_gt', 'ac', 'pc']].values\n",
    "\n",
    "    #read the csv containing pre computed coarse landmarks and the true AC-PC locations\n",
    "    try:\n",
    "        physical_coordinates = np.array([np.float64(x.strip(\"[]\")) for x in img_labels[0][0].split(\",\")] + \n",
    "                             [np.float64(x.strip(\"[]\")) for x in img_labels[0][1].split(\",\")] +\n",
    "                             [np.float64(x.strip(\"[]\")) for x in img_labels[0][2].split(\",\")] +\n",
    "                             [np.float64(x.strip(\"[]\")) for x in img_labels[0][3].split(\",\")])\n",
    "    except IndexError:\n",
    "        sys.exit(f'Coarse and ground-truth AC-PC coordinates not found for scan {scan_id}')\n",
    "\n",
    "    #start processing \n",
    "\n",
    "    #will contain the Gaussian scaling factors per sigma value to assemble full heatmaps during training \n",
    "    scaling_factors_df = pd.DataFrame() \n",
    "    #will contain the coarse and reference standard AC-PC landmarks, both physical and image coordinates \n",
    "    scan_info_df = pd.DataFrame()\n",
    "\n",
    "    id_ = 0 \n",
    "    for deg in rot_angle_combinations:  \n",
    "        if id_ > 0:\n",
    "            #if this is a rotational case\n",
    "            deg_x, deg_y, deg_z = deg\n",
    "\n",
    "            #apply the desired 3D rotation to both the image and the coarse and reference standard AC-PC landmarks\n",
    "            rotated_image, landmarks_transformed = rotate_image(img, physical_coordinates, (deg_x, deg_y, deg_z)) \n",
    "\n",
    "            #get the array data from the rotated volume\n",
    "            img_arr = window_image(sitk.GetArrayFromImage(rotated_image), window_center = 50, window_width = 100)\n",
    "\n",
    "            #convert **rotated** coarse and reference standard AC-PC coordinates from the physical to the image space\n",
    "            ac_true_coordinates = list(rotated_image.TransformPhysicalPointToContinuousIndex(landmarks_transformed[0]))             \n",
    "            pc_true_coordinates = list(rotated_image.TransformPhysicalPointToContinuousIndex(landmarks_transformed[1]))    \n",
    "            ac_coordinates = list(rotated_image.TransformPhysicalPointToContinuousIndex(landmarks_transformed[2]))    \n",
    "            pc_coordinates = list(rotated_image.TransformPhysicalPointToContinuousIndex(landmarks_transformed[3]))\n",
    "\n",
    "            #gather **rotated** physical coordinates of the coarse and reference standard AC-PC\n",
    "            physical_landmarks_ac_true = landmarks_transformed[0]\n",
    "            physical_landmarks_pc_true = landmarks_transformed[1]\n",
    "            physical_landmarks_ac = landmarks_transformed[2]\n",
    "            physical_landmarks_pc = landmarks_transformed[3]\n",
    "\n",
    "        else:\n",
    "            #if processing the original image without rotations\n",
    "            img_arr = window_image(sitk.GetArrayFromImage(img),  window_center = 50, window_width = 100) \n",
    "\n",
    "            #convert coarse and reference standard AC-PC coordinates from the physical to the image space\n",
    "            ac_true_coordinates = list(img.TransformPhysicalPointToContinuousIndex(physical_coordinates[:3]))\n",
    "            pc_true_coordinates = list(img.TransformPhysicalPointToContinuousIndex(physical_coordinates[3:6]))    \n",
    "            ac_coordinates = list(img.TransformPhysicalPointToContinuousIndex(physical_coordinates[6:9]))    \n",
    "            pc_coordinates = list(img.TransformPhysicalPointToContinuousIndex(physical_coordinates[9:]))\n",
    "\n",
    "            #gather physical coordinates of the coarse and reference standard AC-PC\n",
    "            physical_landmarks_ac_true = physical_coordinates[:3]\n",
    "            physical_landmarks_pc_true = physical_coordinates[3:6]\n",
    "            physical_landmarks_ac = physical_coordinates[6:9]\n",
    "            physical_landmarks_pc = physical_coordinates[9:]\n",
    "\n",
    "        #sanity checks to ensure that image coordinates are not negative, because they can't be.\n",
    "        #If you used our notebook for preprocessing and coarse localization, the origin of these images would be at 0,0,0 \n",
    "        #and all these scans are ensured to have a direction cosine of identity. So no image coordinates can be negative \n",
    "        if (ac_true_coordinates[0] < 0) | (ac_true_coordinates[1] < 0) | (ac_true_coordinates[2] < 0):\n",
    "            sys.exit(f'Image coordinates negative for scan {scan_id}. Recheck processing')\n",
    "\n",
    "        if (pc_true_coordinates[0] < 0) | (pc_true_coordinates[1] < 0) | (pc_true_coordinates[2] < 0):\n",
    "            sys.exit(f'Image coordinates negative for scan {scan_id}. Recheck processing')\n",
    "\n",
    "        if (ac_coordinates[0] < 0) | (ac_coordinates[1] < 0) | (ac_coordinates[2] < 0):\n",
    "            sys.exit(f'Image coordinates negative for scan {scan_id}. Recheck processing')\n",
    "\n",
    "        if (pc_coordinates[0] < 0) | (pc_coordinates[1] < 0) | (pc_coordinates[2] < 0):\n",
    "            sys.exit(f'Image coordinates negative for scan {scan_id}. Recheck processing')\n",
    "        \n",
    "        #generate inputs for each rotation. These are essentially 3D patches of the brain scan, cropped around the \n",
    "        #coarse AC-PC landmarks\n",
    "        try:\n",
    "            generate_input_patches(scan_id, id_, img_arr, patch_size, ac_coordinates, pc_coordinates, ip_patches_write_path)\n",
    "        except Exception as e:\n",
    "            sys.exit(f'Issue with input patch generation for scan_id {scan_id}: {e}')\n",
    "\n",
    "        #generate half-processed heatmaps for each rotation. These are intermediately processed, 4 channel heatmaps (AC and PC \n",
    "        #channels/gaussians, both cropped around the coarse AC-PC landmarks). \n",
    "        #This also returns scaling factors that are required to assemble full heatmaps \n",
    "        try: \n",
    "            scaling_factors_scan = heatmap_processing(scan_id, id_, img_arr, patch_size, ac_true_coordinates, pc_true_coordinates,\n",
    "                           ac_coordinates, pc_coordinates, sigma_list, heatmap_patches_write_path)\n",
    "        except Exception as e:\n",
    "            sys.exit(f'Issue with heatmap patch generation for scan_id {scan_id}: {e}')\n",
    "\n",
    "        #put together image coordinates of the coarse localized and true AC-PC landmarks -- along with those corresponding to \n",
    "        #rotated images for augmentation\n",
    "        scan_info_df = pd.DataFrame({'scan_id':[scan_id],\n",
    "                                            'deg':[deg],\n",
    "                                            'rot_id':[id_],\n",
    "                                            'pc':[physical_landmarks_pc],\n",
    "                                            'ac':[physical_landmarks_ac],\n",
    "                                            'pc_true':[physical_landmarks_pc_true],\n",
    "                                            'ac_true':[physical_landmarks_ac_true],\n",
    "                                            'pc_img':[pc_coordinates],\n",
    "                                            'ac_img':[ac_coordinates],\n",
    "                                            'pc_img_true':[pc_true_coordinates],\n",
    "                                            'ac_img_true':[ac_true_coordinates],\n",
    "                                            })\n",
    "\n",
    "\n",
    "        id_ = id_ + 1\n",
    "        \n",
    "        # scaling_factors_write_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        #write the required information for training the 3D-UNet\n",
    "        scaling_factors_scan.to_csv(str(scaling_factors_write_path.resolve()), mode='a', header=not os.path.exists(scaling_factors_write_path), \n",
    "                                   index = False)     \n",
    "        scan_info_df.to_csv(str(scan_info_write_path.resolve()), mode='a', header=not os.path.exists(scan_info_write_path), \n",
    "                           index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd00a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data read and write paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path()\n",
    "\n",
    "#raw nifti location \n",
    "data_path = root / \"brain_vols\" \n",
    "\n",
    "#ground-truth or reference standard AC-PC annotations\n",
    "gt_ann_path =  root / \"acpc_annotations/acpc_gt.csv\" \n",
    "\n",
    "#coarse localized AC-PC landmarks \n",
    "coarse_acpc_path = root / \"acpc_annotations/acpc_coarse.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c15ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains both physical and image coordinates of the coarse localized and reference standard AC-PC. Note that these are\n",
    "#computed for every chosen rotation of the input data for augmentation during training \n",
    "scan_info_write_path = root / \"files_for_unet/scan_info.csv\"\n",
    "\n",
    "#contains the scaling factors for Gaussian heatmaps at different sigma levels. These help assemble the full heatmap on the \n",
    "#fly during training\n",
    "scaling_factors_write_path =  root / \"files_for_unet/scaling_factors_info.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_patches_write_path = root / \"patched_data_4unet/ip_patches\"\n",
    "heatmap_patches_write_path = root / \"patched_data_4unet/op_patches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acpc_df_gt = pd.read_csv(gt_ann_path).drop(columns = 'Unnamed: 0')\n",
    "acpc_df_coarse = pd.read_csv(coarse_acpc_path).drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge coarse localized and true AC-PC landmarks into one file\n",
    "all_landmarks = acpc_df_gt.rename(columns = {'ac':'ac_gt','pc':'pc_gt'}).merge(acpc_df_coarse, how = 'inner', on = 'scan_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1314481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Define the 3D rotations (theta_x, theta_y, and theta_z) needed for augmentation \n",
    "\n",
    "####### Original version used in the paper - generates 108 rotations per scan, to enable random sampling of a chosen\n",
    "####### number of random rotations for augmentation during training - Modify as required\n",
    "# x_rots = [rot for rot in np.arange(-10,12,2.5) if abs(rot) > 3] #rotation around the x-axis\n",
    "# #rotation around the y-axis (chose a limited range due to the naturally constrained rotations of patient heads around \n",
    "# #the anterior-posterior axis)\n",
    "# y_rots = [rot for rot in np.arange(-2.5,3.5,2.5)] \n",
    "# z_rots = [rot for rot in np.arange(-10,12,2.5) if abs(rot) > 3] #rotation around the z axis\n",
    "\n",
    "#Generating 48 rotations per scan for this demonstration\n",
    "x_rots = [rot for rot in np.arange(-5,6,2.5) if abs(rot) > 2] #rotation around the x-axis\n",
    "#rotation around the y-axis (chose a limited range due to the naturally constrained rotations of patient heads around \n",
    "#the anterior-posterior axis)\n",
    "y_rots = [rot for rot in np.arange(-2.5,3.5,2.5)] \n",
    "z_rots = [rot for rot in np.arange(-5,6,2.5) if abs(rot) > 2] #rotation around the z axis\n",
    "\n",
    "#define the combinations\n",
    "rot_angle_combinations = [(x,y,z) for x,y,z in list(product(x_rots,y_rots,z_rots))]\n",
    "\n",
    "#add the unrotated original version (corresponding to rotation 0,0,0)\n",
    "rot_angle_combinations = [(0,0,0)] + rot_angle_combinations\n",
    "print(len(rot_angle_combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_ids = all_landmarks['scan_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scan_ids) \n",
    "#This will depend upon the size of your dataset for training/inference.\n",
    "#Note that there are only 5 scans for the sake of this demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e80be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 32\n",
    "sigma_list = [4, 6, 8, 10, 12, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51d279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Serial processing for bebugging etc. \n",
    "# for scan_id in scan_ids:\n",
    "#     process_scan(scan_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c27f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use parallel processing as it significant speeds up processing times. Note that you may not see gains in this demonstration\n",
    "#as we are using a small number of scans. This will be noticeable when dataset size is increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac223891",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(process_scan, scan_ids)\n",
    "    \n",
    "print([x for x in results])\n",
    "\n",
    "print((time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors_scan = pd.read_csv(str(scaling_factors_write_path.resolve()))\n",
    "scan_info_df = pd.read_csv(str(scan_info_write_path.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac312b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e17e80",
   "metadata": {},
   "source": [
    "Attach full paths to the cropped inputs and half-assembled ground-truth heatmaps to facilitate the data loader for 3D-UNet training, write them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_info_df['scan_path'] = scan_info_df[['scan_id', 'rot_id']].apply(lambda x: os.path.join(x['scan_id'], f\"input_patches_Rot_{x['rot_id']}.npy\"), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_info_df['gt_heatmap_path'] = scan_info_df[['scan_id', 'rot_id']].apply(lambda x: os.path.join(x['scan_id'], f\"hm_patches_Rot_{x['rot_id']}.npy\"), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcfe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors_scan['gt_heatmap_path'] = scaling_factors_scan[['scan_id', 'rot_id']].apply(lambda x: os.path.join(x['scan_id'], f\"hm_patches_Rot_{x['rot_id']}.npy\"), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbd462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scan_info_df['scan_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0261277",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_info_df.to_csv(str(scan_info_write_path.resolve()), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors_scan.to_csv(str(scaling_factors_write_path.resolve()), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bec57-09a1-4539-be59-32eafe94c85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
