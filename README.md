<div align="justify">

# Registration-guided 3D-UNets for AC-PC Landmark Prediction on CT (Potentially Change Title)

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
![Patent Pending](https://img.shields.io/badge/Status-Patent%20Pending-blue)
> This software is **Patent Pending** (US App. No. 18/534,822) and is strictly for **Non-Commercial Academic Use**. See the [License & Patent Notice](#license--patent-notice) section below for details.

This repository provides code to develop and evaluate a framework of image registration informed 3D-UNets to automatically localize the Anterior (AC) and Posterior Commissure (PC) landmarks on non-contrast Computed Tomography (CT) scans. 

**Note:** This repository is a snapshot of the code used to generate the results for the axial reformat-specific AC-PC localization presented in the manuscript. While the core logic is fully functional and reproducible, the codebase is currently being refactored and documented for the final public release.

## Model Availability Disclaimer
As this framework was originally developed using data from the Dept. of Veterans Affairs (VA), we are unable to publicly release the model weights trained on internal VA head CT scans due to patient privacy regulations and data security policies. However, we provide the complete source code and a detailed step-by-step tutorial to enable researchers to train the model using their own datasets.

## Data Requirements
We developed this framework on a structurally diverse set of 400+ non-contrast CT scans from 340 patients with Normal Pressure Hydrocephalus (NPH), Alzheimer's Disease (AD), post-traumatic volume loss (PTVL), and headache (HC) by consecutively including patients to maximize training data size. We also employed rotational augmentations in the training data (emperically determined to be optimal at 14 3D rotations per scan) to improve generalization. As this model generalized to two external datasets, we recommend that researchers aim to include at least ~100 scans per neurological condition, with sufficient data augmentation. 

The AC-PC reference standard that we used as ground-truth to train our models was generated by a team of multiple annotators, guided by a protocol developed by a board-certified neuroradiologist. The landmarks were annotated on the central intercommissural line (CIL). See [Choi et al. 2013](https://pubmed.ncbi.nlm.nih.gov/23901324/) [1] for visualizing the landmarks on the CIL. We recommend that researchers seeking to develop their own in-house registration-guided 3D-UNet framework for AC-PC localization use a similar multi-annotator validated reference standard. 

## System and Add-on Requirements
### Coarse Localization
The coarse-localization step for our framework was run fully within 3D Slicer using a Jupyter Notebook interface, which can be found in [CoarseLocalizationSlicer.ipynb](./CoarseLocalizationSlicer.ipynb). We used [3D Slicer version 5.6.2](https://download.slicer.org/?version=5.6.2) [2]. The following extensions to 3D Slicer, which can be downloaded from 3D-Slicer (View > Extensions Manager) are required: 
1. [SlicerJupyter](https://github.com/Slicer/SlicerJupyter)
2. [SlicerElastix](https://github.com/lassoan/SlicerElastix)
3. [SurfaceWrapSolidify](https://github.com/sebastianandress/Slicer-SurfaceWrapSolidify)
 
### Fine Localization
Our 3D-UNet models were trained with data of scale described above on a Linux machine (Ubuntu 24.04.3 LTS) with the following specifications:\
CPU: Intel(R) Core(TM) i9-10850K CPU @ 3.60GHz 20M Cache\
Cores: 10 Cores / 20 Threads\
Memory: 32GB\
GPU: NVIDIA GeForce RTX 3080 (10GB VRAM)

*Note on keeping training times reasonable with large-scale image data*: The registration-guided 3D-UNets require 2-channel (for the two landmarks: AC and PC) 3D-patches of image data as input and 6-channel 3D-patches of ground-truth heatmaps (2 landmarks x 3 channels \[AC, PC, background] = 6 operational channels) for supervised training. Our experience with assembling the inputs and outputs on the fly with dataloaders resulted in very long training times, where multiple model versions have to be evaluated for hyperparameter tuning. Therefore, we assemble intermediately processed data which is first fully read into CPU memory. See [Preprocessing_3DUNet](Preprocessing_3DUNet.ipynb) for the implementation of this preprocessing. During training, batches of data were fully processed and moved into GPU memory. 

## Schematic of the Registration-guided 3D-UNet Framework
![System Architecture Diagram](assets/Registration-guided 3D-UNet Framework.jpg)
Figure 1. Overview of the AC-PC Localization Methodology. Coarse landmarks inferred via image registration (coarse localization), guide selection of image patches which are input to the 3D-UNet to perform heatmap regression around the true AC and PC landmarks, along with a background heatmap. Patch and channel specific predictions are unstacked and normalized, followed by derivation of AC-PC predictions (fine localization) as the mean location of active voxels in the regressed heatmaps. AC = Anterior Commissure, PC = Posterior-Commissure, BG = Background, ps = patch-size, BN = Batch-Normalization, ReLU = Rectified Linear Unit. Note that processing is in 3D, and 2D input slices and heatmaps are indicated for demonstration purposes. 

## Illustration of AC-PC landmark prediction on a sample CT scan 
![AC-PC Illustration](assets/ACPCLocalization.jpg)
Figure 2. Cases of good AC-PC localization on representative high head-tilt test-set scans of patients with NPH, AD, HC, and PTVL. Reference standard (yellow), coarse (pink), and fine (green) AC-PC localization are depicted for each neurological condition, on cropped images from axial and sagittal reformats of each scan (as indicated by the magenta box for the NPH scan), are shown for each neurological condition. A line-segment connecting the AC-PC landmarks not being visible indicates that the specific line was out of the plane being shown. AC-PC landmarks (cyan) are also visualized on an MRI template for reference. AC = Anterior Commissure, PC = Posterior-Commissure, NPH = Normal Pressure Hydrocephalus, AD = Alzheimer's Dementia, PTVL = Post-traumatic volume loss, HC = headache, CIL = Central intercommissural line. Coarse/fine localized AC and PC REs were 4/2.33 mm and 1.27/0.44 mm, 4.63/1.78 mm and 0.69/0.46 mm, 4.38/2.17 mm and 0.84/0.88 mm, and 3.65/0.91 mm and 1.18/0.58 mm for the NPH, AD, PTVL, and HC scans, respectively. Head-tilts in the YZ/XY planes were 25.68°/1.51°, 21.65°/5.44°, 8.65°/8°, and 11.84°/0°, for the NPH, AD, PTVL, and AD scans, respectively.  

<!-- Figure 2. Visualization of AC-PC prediction on a representative head CT scan obtained from the public CQ500 dataset [3]. This 5-mm CT scan was selected based on the accompanying radiology reports indicating no intracranial abnormalities, serving here as a representative example of normal anatomy. The coarse AC-PC landmarks derived via image registration (in *yellow*), manually annotated reference standard landmarks (in *yellow*), and fine localized landmarks from the registration-guided 3D-UNet (in *green*) are shown. Overall AC/PC localization error (mean radial distance between the fine localized and reference standard landmarks) were 1.7/1.25 mm. Note: This volume is used solely for illustrative purposes to demonstrate the reference standard alongside coarse and fine-localized predictions; it was not included in the training, validation, or testing cohorts used in this study. The CQ500 scan is displayed here for demonstration because the clinical datasets used in this study are restricted from public display due to institutional privacy regulations. -->

## Repository Structure
Note that while we provide code for developing this framework on axial reformats, as they are ubiquitously acquired, they can be readily adapted for coronal and sagittal reformats. 
### Code Organization
| File | Description |
| :--- | :--- |
| `CoarseLocalizationSlicer.ipynb` | Notebook implementing the coarse localization step |
| `Preprocessing_3DUNet.ipynb` | Notebook implementing all preprocessing necessary for training and testing the 3D-UNet for fine localization|
| `data_utils.py` | PyTorch Datasets and Dataloaders for AC-PC landmark localization on head CT data |
| `model.py` | Contains the 3D UNet architecture (adapted from Wolny et al. [4]) |
| `loss.py` | Custom loss function used during training |
| `train_hptune_test.py` | Python file for hyper-parameter tuning using nested cross validation |
| `trainWaug_test.py` | Python file for training models at different augmentation scales, after fixing hyperparameters from the previous step |

### Data Setup
**This repository does not contain head CT data** except for the CT-template reproduced from [Rajashekhar et al., 2020](https://www.nature.com/articles/s41597-020-0379-9) [5]. You must create the following folder structure locally and populate it with your own files to run the code.

Create the following folders in the root directory, and structure them as follows:
```text
AC-PC-Prediction/
├── raw_data/                     # INPUT: Place your .nii scans here
│   ├── patient_001.nii
│   └── patient_002.nii
│
├── ct_template/                  # INPUT: Reference atlas files
│   ├── miplab_to_mni_sym_warp.nii.gz
│   └── miplab-ncct_sym_brain.nii.gz
│
├── annotations/                  # OUTPUT: Generated by processes in CoarseLocalizationSlicer.ipnyb. 'acpc_gt.csv' would contain reference standard AC-PC landmarks. 
│   ├── acpc_screenshots/
│   ├── acpc_coarse.csv
│   └── acpc_gt.csv
│
├── brain_vols/                   # OUTPUT: Generated by Preprocessing_3DUNet (skull stripped head CT)
│   ├── patient_001_brain.nii
│   └── ...
│
├── patched_data_4unet/           # OUTPUT: i/p, o/p patches for training the 3D-UNet, generated by processes in Preprocessing_3DUNet.ipynb
│   ├── ip_patches/
│   │   └── patient_001/
│   └── op_patches/
│       └── patient_001/
│
├── files_for_unet/               # OUTPUT: Information required for 3D-UNet training, generated by processes in Preprocessing_3DUNet.ipynb
│   ├── scaling_factors_info.csv
│   └── scan_info.csv
│
├── unet_results_hp_optim/        # OUTPUT: Generated by train_hptune_test.py, contains results of hyperparameter tuning (5-fold CV)
│   ├── trial_results.csv         # Main record required for selecting the optimal hyperparameters
│   └── ...
│
└── unet_results_aug/             # OUTPUT: Generated by trainWaug_test.py, contains results of training models at increasing augmentation levels
    ├── AugmentedTimes2/
    │   └── tracked_test_set_predictions.csv
    ├── ...
    └── AugmentedTimes4/
``` 

## Acknowledgments

This work utilized **3D Slicer** (https://www.slicer.org/) for image preprocessing and obtaining coarse localized AC-PC landmarks via image registration. If you use this code for your research, please consider citing 3D Slicer in your work [2].

## License & Patent Notice

**Copyright:**
This project is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)**. 

**Patent:**
The methods and algorithms implemented in this software are the subject of **US Patent Application No. 18/534,822**. 

Commercial use of this software, or the methods described herein, is strictly prohibited without a separate commercial license. For commercial licensing inquiries, please contact: uzma@samadani.com.

**Third-Party Component:**
This repository contains code adapted from *pytorch-3dunet* by Adrian Wolny, used under the MIT License. See [model.py](model.py) for details.

**References**
1. Choi SH, Chi JG, Kim YB, Cho ZH. Anterior commissure--posterior commissure revisited. Korean J Radiol. 2013 Jul-Aug;14(4):653-61. doi: 10.3348/kjr.2013.14.4.653. Epub 2013 Jul 17. PMID: 23901324; PMCID: PMC3725361.
2. Fedorov A, Beichel R, Kalpathy-Cramer J, Finet J, Fillion-Robin JC, Pujol S, Bauer C, Jennings D, Fennessy F, Sonka M, Buatti J, Aylward S, Miller JV, Pieper S, Kikinis R. 3D Slicer as an image computing platform for the Quantitative Imaging Network. Magn Reson Imaging. 2012 Nov;30(9):1323-41. doi: 10.1016/j.mri.2012.05.001. Epub 2012 Jul 6. PMID: 22770690; PMCID: PMC3466397.
3. Chilamkurthy, S., Ghosh, R., Tanamala, S., et al. "Deep learning algorithms for detection of critical findings in head CT scans." arXiv preprint arXiv:1803.05854 (2018).
4. Wolny A, Cerrone L, Vijayan A, Tofanelli R, Barro AV, Louveaux M, Wenzl C, Strauss S, Wilson-Sánchez D, Lymbouridou R, Steigleder SS, Pape C, Bailoni A, Duran-Nebreda S, Bassel GW, Lohmann JU, Tsiantis M, Hamprecht FA, Schneitz K, Maizel A, Kreshuk A. Accurate and versatile 3D segmentation of plant tissues at cellular resolution. Elife. 2020 Jul 29;9:e57613. doi: 10.7554/eLife.57613. PMID: 32723478; PMCID: PMC7447435.
5. Rajashekar D, Wilms M, MacDonald ME, Ehrhardt J, Mouches P, Frayne R, Hill MD, Forkert ND. High-resolution T2-FLAIR and non-contrast CT brain atlas of the elderly. Sci Data. 2020 Feb 17;7(1):56. doi: 10.1038/s41597-020-0379-9. PMID: 32066734; PMCID: PMC7026039.

</div>
