# Registration-guided 3D-UNets for AC-PC Landmark Prediction on CT

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
![Patent Pending](https://img.shields.io/badge/Status-Patent%20Pending-blue)
> This software is **Patent Pending** (US App. No. 18/534,822) and is strictly for **Non-Commercial Academic Use**. See the [License & Patent Notice](#license--patent-notice) section below for details.

This repository provides code to develop and evaluate a framework of image registration informed 3D-UNets to automatically localize the Anterior (AC) and Posterior Commissure (PC) landmarks on non-contrast Computed Tomography (CT) scans. 

## Model Availability Disclaimer
As this framework was originally developed using data from the Dept. of Veterans Affairs (VA), we are unable to publicly release the model weights trained on internal VA head CT scans due to patient privacy regulations and data security policies. However, we provide the complete source code and a detailed step-by-step tutorial to enable researchers to train the model using their own datasets.

## Data Requirements
We developed this framework on a structurally diverse set of 400+ non-contrast CT scans from 340 patients with Normal Pressure Hydrocephalus (NPH), Alzheimer's Disease (AD), post-traumatic volume loss (PTVL), and headache (HC) by consecutively including patients to maximize training data size. We also employ rotational augmentations in the training data (emperically determined to be optimal at 14 3D rotations per scan) to improve generalization. As this model generalized to two external datasets, we recommend that researchers aim to include at least ~100 scans per neurological condition, with sufficient data augmentation. 

The AC-PC reference standard that we used as ground-truth to train our models were generated by a team of multiple annotators, guided by a protocol developed by a board-certified neuroradiologist. The landmarks were annotated on the central intercommissural line (CIL). Further details can be found in .... 

## System and Add-on Requirements
### Coarse Localization
The coarse-localization step for our framework was run fully within 3D Slicer using a Jupyter Notebook interface (). See 'preprocessing_README' for details on image preprocessing. We used 3D Slicer version 5.6.2 (https://download.slicer.org/?version=5.6.2). The following extensions to 3D Slicer, which can be downloaded from 3D-Slicer (View > Extensions Manager) are required: 
1. SlicerJupyter (https://github.com/Slicer/SlicerJupyter)
2. SlicerElastix (https://github.com/lassoan/SlicerElastix)
3. SurfaceWrapSolidify (https://github.com/sebastianandress/Slicer-SurfaceWrapSolidify)

SlicerNeuro (https://github.com/Slicer/SlicerNeuro) offers the "ACPC Transform" module to visualize an AC-PC transformed CT scan using AC/PC predictions from our framework. Note that the .... modules, which get automatically installed with SlicerNeuro may interfere with the workflow if they are not removed manually. 
 
### Fine Localization
Our 3D-UNet models was trained with data of scale described above on a Linux machine (Ubuntu 24.04.3 LTS) with the following specifications:\
CPU: Intel(R) Core(TM) i9-10850K CPU @ 3.60GHz 20M Cache\
Cores: 10 Cores / 20 Threads\
Memory: 32GB\
GPU: NVIDIA GeForce RTX 3080 (10GB VRAM)

*Note on keeping training times reasonable with large-scale image data: The registration-guided 3D-UNets require 2-channel (for the two landmarks: AC and PC) 3D-patches of image data as input and 6-channel 3D-patches of ground-truth heatmaps (2 landmarks \times 3 channels: AC, PC, background) for supervised training. Our experience with assembling the inputs and outputs on the fly with dataloaders resulted in very long training times, where multiple model versions have to be evaluated for hyperparameter tuning. Therefore, we assemble intermediately processed data which is first fully read into CPU memory. During training, batches of data were fully processed and moved into GPU memory.* 

## Schematic of the Registration-guided 3D-UNet Framework
![System Architecture Diagram](assets/Registration-guided-3D-UNet-Framework.jpg)
Coarse landmarks inferred via image registration (coarse localization), guide selection of image patches which are input to the 3D-UNet to perform heatmap regression around the true AC and PC landmarks, along with a background heatmap. Patch and channel specific predictions are unstacked and normalized, followed by derivation of AC-PC predictions (fine localization) as the mean location of active voxels in the regressed heatmaps. AC = Anterior Commissure, PC = Posterior-Commissure, BG = Background, ps = patch-size, BN = Batch-Normalization, ReLU = Rectified Linear Unit. Note that processing is in 3D, and 2D input slices and heatmaps are indicated for demonstration purposes. 

## Illustration of AC-PC landmark prediction on a sample CT scan 
Figure 1 shows an example of AC-PC prediction on sample CT scans of a patient with Normal Pressure Hydrocephalus (NPH) and a normal patient. N 


## License & Patent Notice

**Copyright:**
This project is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)**. 

**Patents:**
The methods and algorithms implemented in this software are the subject of **US Patent Application No. 18/534,822**. 

Commercial use of this software, or the methods described herein, is strictly prohibited without a separate commercial license. For commercial licensing inquiries, please contact: uzma@samadani.com.

**Third-Party Components:**
This repository contains code adapted from *pytorch-3dunet* by Adrian Wolny, used under the MIT License. See `model.py` for details.
